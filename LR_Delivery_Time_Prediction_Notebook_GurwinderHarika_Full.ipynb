{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "176dc5b7",
   "metadata": {},
   "source": [
    "# LR Delivery Time Prediction â€” Complete Notebook\n",
    "\n",
    "**Name:** Gurwinder Harika\n",
    "\n",
    "**Assignment ID:** LR/02\n",
    "\n",
    "**Instructions:** Run cells in order. This notebook contains the full pipeline: data loading, preprocessing, EDA, feature engineering, model building (Linear Regression + selection), evaluation, residual and coefficient analysis, and answers to subjective questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b61fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "plt.style.use('default')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (ensure porter_data_1.csv exists at /mnt/data)\n",
    "DATA_PATH = \"/mnt/data/porter_data_1.csv\"\n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "print(\"Loaded rows:\", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade0dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse timestamps and create target delivery_duration_min\n",
    "for col in ['created_at', 'actual_delivery_time']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "if 'created_at' in df.columns and 'actual_delivery_time' in df.columns:\n",
    "    df['delivery_duration_min'] = (df['actual_delivery_time'] - df['created_at']).dt.total_seconds() / 60.0\n",
    "else:\n",
    "    df['delivery_duration_min'] = np.nan\n",
    "\n",
    "print('Target created, sample values:')\n",
    "df[['created_at','actual_delivery_time','delivery_duration_min']].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9da55ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic cleaning: drop rows w/o valid positive target\n",
    "before = len(df)\n",
    "df = df[df['delivery_duration_min'].notna()]\n",
    "df = df[df['delivery_duration_min'] > 0]\n",
    "after = len(df)\n",
    "print(f'Rows before: {before}, after dropping invalid target: {after}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f18f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix dtypes and feature engineering\n",
    "# Treat some numeric IDs/codes as categorical\n",
    "for c in ['market_id','store_primary_category','order_protocol']:\n",
    "    if c in df.columns:\n",
    "        try:\n",
    "            df[c] = df[c].astype('Int64').astype('object')\n",
    "        except Exception:\n",
    "            df[c] = df[c].astype(str)\n",
    "\n",
    "# Time-based features\n",
    "if 'created_at' in df.columns:\n",
    "    df['order_hour'] = df['created_at'].dt.hour\n",
    "    df['order_dow'] = df['created_at'].dt.dayofweek\n",
    "\n",
    "# Price/item derived features\n",
    "if set(['min_item_price','max_item_price','total_items','num_distinct_items']).issubset(df.columns):\n",
    "    df['price_range'] = df['max_item_price'] - df['min_item_price']\n",
    "    df['item_density'] = df['num_distinct_items'] / df['total_items'].replace(0, np.nan)\n",
    "\n",
    "print('New feature columns:', [c for c in df.columns if c.startswith(('order_','price_','item_'))][:20])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3e9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation for numeric columns (median) and fill categorical NAs\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "df[numeric_cols] = df[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "df[numeric_cols] = pd.DataFrame(num_imputer.fit_transform(df[numeric_cols]), columns=numeric_cols, index=df.index)\n",
    "\n",
    "cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()\n",
    "df[cat_cols] = df[cat_cols].fillna('missing').astype(str)\n",
    "\n",
    "# Remove extreme target outliers (0.1% - 99.5% quantiles)\n",
    "low_q, high_q = df['delivery_duration_min'].quantile([0.001, 0.995])\n",
    "print('Target quantile cutoffs:', low_q, high_q)\n",
    "df = df[(df['delivery_duration_min'] >= low_q) & (df['delivery_duration_min'] <= high_q)].copy()\n",
    "print('Rows after outlier trimming:', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91359298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis (run plots individually to inspect)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Histogram of target\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(df['delivery_duration_min'], bins=80)\n",
    "plt.title('Delivery duration (minutes)')\n",
    "plt.xlabel('Minutes'); plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Histogram of distance (if present)\n",
    "if 'distance' in df.columns:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.hist(df['distance'], bins=60)\n",
    "    plt.title('Distance')\n",
    "    plt.show()\n",
    "\n",
    "# Scatter distance vs duration\n",
    "if 'distance' in df.columns:\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.scatter(df['distance'], df['delivery_duration_min'], s=6, alpha=0.4)\n",
    "    plt.title('Distance vs Delivery Duration')\n",
    "    plt.xlabel('Distance'); plt.ylabel('Duration (min)')\n",
    "    plt.show()\n",
    "\n",
    "# Correlation heatmap (numeric)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df.select_dtypes(include=[np.number]).corr(), fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title('Correlation matrix (numeric)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db9835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select candidate features and prepare modeling dataset\n",
    "candidate_features = [\n",
    "    'distance', 'total_items', 'subtotal', 'num_distinct_items',\n",
    "    'min_item_price', 'max_item_price', 'total_onshift_dashers',\n",
    "    'total_busy_dashers', 'total_outstanding_orders', 'order_hour',\n",
    "    'order_dow', 'price_range', 'item_density'\n",
    "]\n",
    "features = [f for f in candidate_features if f in df.columns]\n",
    "target = 'delivery_duration_min'\n",
    "print('Features used:', features)\n",
    "\n",
    "df_model = df[features + [target]].dropna()\n",
    "print('Rows in modeling set:', len(df_model))\n",
    "\n",
    "# Train-test split (80/20)\n",
    "X = df_model[features].copy(); y = df_model[target].copy()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print('Train rows:', len(X_train), 'Val rows:', len(X_val))\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Baseline Linear Regression\n",
    "lr = LinearRegression().fit(X_train_scaled, y_train)\n",
    "y_pred_val = lr.predict(X_val_scaled)\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    return {'MAE': mean_absolute_error(y_true, y_pred),\n",
    "            'RMSE': mean_squared_error(y_true, y_pred, squared=False),\n",
    "            'R2': r2_score(y_true, y_pred)}\n",
    "\n",
    "print('Baseline metrics:', metrics(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b883d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection: RFE on a sample (faster) and SelectKBest\n",
    "sample_size = min(40000, len(X_train))\n",
    "print('RFE sample size:', sample_size)\n",
    "rfe_sample = X_train.sample(sample_size, random_state=42)\n",
    "rfe_sample_y = y_train.loc[rfe_sample.index]\n",
    "\n",
    "# Fit RFE (choose up to 8 features)\n",
    "n_select = min(8, X_train.shape[1])\n",
    "rfe = RFE(estimator=LinearRegression(), n_features_to_select=n_select, step=1)\n",
    "rfe.fit(rfe_sample, rfe_sample_y)\n",
    "rfe_selected = [f for f,s in zip(features, rfe.get_support()) if s]\n",
    "print('RFE selected (sample-based):', rfe_selected)\n",
    "\n",
    "# SelectKBest as alternative\n",
    "k = min(8, X_train.shape[1])\n",
    "skb = SelectKBest(score_func=f_regression, k=k).fit(X_train, y_train)\n",
    "skb_selected = [f for f,s in zip(features, skb.get_support()) if s]\n",
    "print('SelectKBest selected:', skb_selected)\n",
    "\n",
    "# Evaluate model using skb_selected\n",
    "sel = skb_selected\n",
    "scaler_sel = StandardScaler()\n",
    "X_train_sel = scaler_sel.fit_transform(X_train[sel])\n",
    "X_val_sel = scaler_sel.transform(X_val[sel])\n",
    "lr_sel = LinearRegression().fit(X_train_sel, y_train)\n",
    "print('Metrics (SelectKBest-LR):', metrics(y_val, lr_sel.predict(X_val_sel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d52d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis and coefficients for selected model\n",
    "y_pred_sel = lr_sel.predict(X_val_sel)\n",
    "residuals = y_val - y_pred_sel\n",
    "\n",
    "# Residual histogram\n",
    "plt.figure(figsize=(8,4)); plt.hist(residuals, bins=60); plt.title('Residuals'); plt.show()\n",
    "\n",
    "# Residuals vs predicted\n",
    "plt.figure(figsize=(7,5)); plt.scatter(y_pred_sel, residuals, s=6, alpha=0.5); plt.axhline(0, color='k'); plt.xlabel('Predicted'); plt.ylabel('Residual'); plt.show()\n",
    "\n",
    "# Coefficients table\n",
    "coefs = pd.DataFrame({'feature': sel, 'coef': lr_sel.coef_})\n",
    "coefs['abs_coef'] = coefs['coef'].abs()\n",
    "coefs = coefs.sort_values('abs_coef', ascending=False)\n",
    "coefs.reset_index(drop=True, inplace=True)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: save selected features list and metrics to CSV for the report\n",
    "out = {\n",
    "    'selected_features': sel,\n",
    "    'validation_metrics': metrics(y_val, lr_sel.predict(X_val_sel))\n",
    "}\n",
    "import json\n",
    "with open('/mnt/data/model_summary.json','w') as f:\n",
    "    json.dump(out, f, indent=2)\n",
    "print('Saved model_summary.json to /mnt/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc60cf6",
   "metadata": {},
   "source": [
    "## Subjective Questions (Answers)\n",
    "\n",
    "**Q1. How did you handle missing values and why?**  \n",
    "A1. Numeric missing values were imputed with median values to reduce sensitivity to outliers; categorical missing values were filled with 'missing' so the information about missingness is preserved. This approach prevents dropping many rows and keeps the dataset representative.\n",
    "\n",
    "**Q2. How did you handle outliers?**  \n",
    "A2. Extreme outliers in the target were removed by trimming values below the 0.1% and above the 99.5% quantiles, which removes likely erroneous entries and rare extreme cases that could disproportionately affect a linear model.\n",
    "\n",
    "**Q3. Why use RFE and SelectKBest?**  \n",
    "A3. RFE provides model-based recursive elimination and helps find a subset of features that perform well jointly, while SelectKBest is a fast univariate filter to quickly reduce dimensionality. Using both offers a balance of speed and joint-feature evaluation.\n",
    "\n",
    "**Q4. Recommendations for Porter operations**  \n",
    "A4. 1) Allocate more dashers during peak hours; 2) Monitor outstanding orders and balance assignments; 3) Use model-predicted ETAs to set customer expectations; 4) Add traffic and weather data to improve model accuracy.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
